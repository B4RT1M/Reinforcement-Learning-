{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ass_04.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TtCHM1_AlY8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "50b44762-ce2d-4ca7-b733-312c919d1a33"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXaQx18l_PWB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "544da037-eeaa-4174-d343-484643dd8789"
      },
      "source": [
        "!pip install gym\n",
        "!apt-get install python-opengl -y\n",
        "!apt install xvfb -y\n",
        "!pip install gym[atari]\n",
        "!pip install pyvirtualdisplay\n",
        "!conda install piglet\n",
        "!pip install pystan\n",
        "!conda install swig\n",
        "!pip install box2d-py\n",
        "!pip install gym[Box_2D]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gym in /usr/local/lib/python3.6/dist-packages (0.17.2)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym) (1.5.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym) (1.4.1)\n",
            "Requirement already satisfied: cloudpickle<1.4.0,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.16.0)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'apt autoremove' to remove it.\n",
            "Suggested packages:\n",
            "  libgle3\n",
            "The following NEW packages will be installed:\n",
            "  python-opengl\n",
            "0 upgraded, 1 newly installed, 0 to remove and 59 not upgraded.\n",
            "Need to get 496 kB of archives.\n",
            "After this operation, 5,416 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python-opengl all 3.1.0+dfsg-1 [496 kB]\n",
            "Fetched 496 kB in 0s (5,439 kB/s)\n",
            "Selecting previously unselected package python-opengl.\n",
            "(Reading database ... 144328 files and directories currently installed.)\n",
            "Preparing to unpack .../python-opengl_3.1.0+dfsg-1_all.deb ...\n",
            "Unpacking python-opengl (3.1.0+dfsg-1) ...\n",
            "Setting up python-opengl (3.1.0+dfsg-1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  xvfb\n",
            "0 upgraded, 1 newly installed, 0 to remove and 59 not upgraded.\n",
            "Need to get 784 kB of archives.\n",
            "After this operation, 2,266 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 xvfb amd64 2:1.19.6-1ubuntu4.4 [784 kB]\n",
            "Fetched 784 kB in 0s (8,596 kB/s)\n",
            "Selecting previously unselected package xvfb.\n",
            "(Reading database ... 146683 files and directories currently installed.)\n",
            "Preparing to unpack .../xvfb_2%3a1.19.6-1ubuntu4.4_amd64.deb ...\n",
            "Unpacking xvfb (2:1.19.6-1ubuntu4.4) ...\n",
            "Setting up xvfb (2:1.19.6-1ubuntu4.4) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Requirement already satisfied: gym[atari] in /usr/local/lib/python3.6/dist-packages (0.17.2)\n",
            "Requirement already satisfied: cloudpickle<1.4.0,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym[atari]) (1.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym[atari]) (1.4.1)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym[atari]) (1.5.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym[atari]) (1.18.5)\n",
            "Requirement already satisfied: atari-py~=0.2.0; extra == \"atari\" in /usr/local/lib/python3.6/dist-packages (from gym[atari]) (0.2.6)\n",
            "Requirement already satisfied: opencv-python; extra == \"atari\" in /usr/local/lib/python3.6/dist-packages (from gym[atari]) (4.1.2.30)\n",
            "Requirement already satisfied: Pillow; extra == \"atari\" in /usr/local/lib/python3.6/dist-packages (from gym[atari]) (7.0.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[atari]) (0.16.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from atari-py~=0.2.0; extra == \"atari\"->gym[atari]) (1.12.0)\n",
            "Collecting pyvirtualdisplay\n",
            "  Downloading https://files.pythonhosted.org/packages/d0/8a/643043cc70791367bee2d19eb20e00ed1a246ac48e5dbe57bbbcc8be40a9/PyVirtualDisplay-1.3.2-py2.py3-none-any.whl\n",
            "Collecting EasyProcess\n",
            "  Downloading https://files.pythonhosted.org/packages/48/3c/75573613641c90c6d094059ac28adb748560d99bd27ee6f80cce398f404e/EasyProcess-0.3-py2.py3-none-any.whl\n",
            "Installing collected packages: EasyProcess, pyvirtualdisplay\n",
            "Successfully installed EasyProcess-0.3 pyvirtualdisplay-1.3.2\n",
            "/bin/bash: conda: command not found\n",
            "Requirement already satisfied: pystan in /usr/local/lib/python3.6/dist-packages (2.19.1.1)\n",
            "Requirement already satisfied: Cython!=0.25.1,>=0.22 in /usr/local/lib/python3.6/dist-packages (from pystan) (0.29.20)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from pystan) (1.18.5)\n",
            "/bin/bash: conda: command not found\n",
            "Collecting box2d-py\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/06/bd/6cdc3fd994b0649dcf5d9bad85bd9e26172308bbe9a421bfc6fdbf5081a6/box2d_py-2.3.8-cp36-cp36m-manylinux1_x86_64.whl (448kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 7.3MB/s \n",
            "\u001b[?25hInstalling collected packages: box2d-py\n",
            "Successfully installed box2d-py-2.3.8\n",
            "Requirement already satisfied: gym[Box_2D] in /usr/local/lib/python3.6/dist-packages (0.17.2)\n",
            "\u001b[33m  WARNING: gym 0.17.2 does not provide the extra 'box_2d'\u001b[0m\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym[Box_2D]) (1.18.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym[Box_2D]) (1.4.1)\n",
            "Requirement already satisfied: cloudpickle<1.4.0,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym[Box_2D]) (1.3.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym[Box_2D]) (1.5.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[Box_2D]) (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxnspi1VASnd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7d7589e3-1fcf-4392-e130-8d8ab2407648"
      },
      "source": [
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(1400, 900))\n",
        "display.start()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyvirtualdisplay.display.Display at 0x7f208de24240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbbKVV62AVbm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This code creates a virtual display to draw game images on. \n",
        "# If you are running locally, just ignore it\n",
        "import os\n",
        "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\"))==0:\n",
        "    !bash ../xvfb start\n",
        "    %env DISPLAY=:1"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8EceRvHAplG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "2ad2df04-46d7-4d70-9f39-c1886a2ee171"
      },
      "source": [
        "import math, random\n",
        "import gym\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.autograd as autograd \n",
        "import torch.nn.functional as F\n",
        "from collections import deque\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "get_ipython().run_line_magic('matplotlib', 'inline')\n",
        "\n",
        "\n",
        "#!pip install gym[LunarLander]\n",
        "class ReplayBuffer(object):\n",
        "    def __init__(self, capacity):\n",
        "        self.buffer = deque(maxlen=capacity)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.buffer)\n",
        "\n",
        "    def push(self, state, action, reward, next_state, done):\n",
        "        '''Add new samples to replay buffer'''\n",
        "        experience = (state, action, reward, next_state, done)\n",
        "        self.buffer.append(experience)\n",
        "        # record the dimension of the state\n",
        "        self.state_dim = state\n",
        "    \n",
        "    def sample(self, batch_size):\n",
        "        ''' sample a batch uniformly from replay buffer, sample without replacement.\n",
        "            Return a tuple (state_batch, action_batch, reward_batch, next_state_batch, done_batch), where\n",
        "            state_batch, next_state_batch: 2D array, [batch_size,state_dim]\n",
        "            action_batch, reward_batch, done_batch: 1D array [batch_size]\n",
        "            Note : the order in these arrays must be matched. \n",
        "            i.e. state_batch = [S_1,S_2,S_3,...S_n]\n",
        "                 action_batch = [a_1,a_2,a_3....a_n] , n = batch_size, the same for the rest three batches\n",
        "            Useful function: np.empty() for initializing N-dim array\n",
        "                            random.sample() for sampling without replacement\n",
        "        '''\n",
        "\n",
        "        # first initialize\n",
        "        #state_batch = np.empty([batch_size,state_d])\n",
        "        #action_batch = np.empty([batch_size])\n",
        "        #reward_batch = np.empty([batch_size])\n",
        "        #next_state_batch = np.empty([batch_size,state_d])\n",
        "        #done_batch = np.empty([batch_size])\n",
        "\n",
        "        # Take #batch_size samples from the replay buffer and write into different arrays.\n",
        "        index = np.random.choice(len(self.buffer), batch_size, replace = False)\n",
        "        state_batch, action_batch, reward_batch, next_state_batch, done_batch = zip(*[self.buffer[idx] for idx in index])\n",
        "        \n",
        "        #return np.concatenate(state_batch), np.array(action_batch), np.array(reward_batch) , np.concatenate(next_state_batch), np.array(done_batch)\n",
        "        return np.array(state_batch), np.array(action_batch), np.array(reward_batch) , np.array(next_state_batch), np.array(done_batch)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class DQN(nn.Module):\n",
        "    def __init__(self, num_inputs, num_actions):\n",
        "        super(DQN, self).__init__()  \n",
        "        ''' To Do: Create the following network architecture:\n",
        "            (1) The first input layer, a fully connected (FC) layer with (input_dim*128), followed by a PReLU layer, see literature for how PRelu works\n",
        "            (2) A hidden layer, also FC, 128*64, and followed by PRELU\n",
        "            (3) The output layer, FC layer, (64*number_of_actions) , no activations, as the output approximates the q(s,a)\n",
        "            Useful function: nn.Sequential() , nn.Linear(), nn.PReLU()\n",
        "        '''\n",
        "        self.layers = torch.nn.Sequential(\n",
        "                        torch.nn.Linear(num_inputs, 128),\n",
        "                        torch.nn.PReLU(),\n",
        "                        torch.nn.Linear(128,64),\n",
        "                        torch.nn.PReLU(),\n",
        "                        torch.nn.Linear(64, num_actions))\n",
        "        \n",
        "        \n",
        "    def forward(self, x):\n",
        "        ''' Retrieve the approximated q(s,a) for the given input x=(s,a)\n",
        "        '''\n",
        "        return self.layers(x)\n",
        "    \n",
        "    def act(self, state, epsilon):\n",
        "        ''' TODO: Perform epislon greedy exploration strategy here,\n",
        "            Return : action index in discrete action space, type(action) = int\n",
        "            You will need to call the function: self.forward(state)\n",
        "        '''\n",
        "        state = torch.FloatTensor(np.float32(state)).to(device)\n",
        "        #print(state.shape)\n",
        "        if np.random.random() <= epsilon:\n",
        "          with torch.no_grad():\n",
        "            action = random.randrange(env.action_space.n)\n",
        "            #action = int(action)\n",
        "        else: \n",
        "          with torch.no_grad():\n",
        "            #state   = torch.FloatTensor(state).unsqueeze(0)\n",
        "            q_value = self.forward(state)\n",
        "            #print(q_value)\n",
        "            #print('shape of the q_value')\n",
        "            #print(q_value.shape)\n",
        "            #action = torch.max(q_value, 1)[1].data.numpy()\n",
        "            #action = action[0] if state == 0 else action.reshape(state)\n",
        "            #action = q_value.max(1)[1].data[0]\n",
        "            action = np.argmax(q_value.cpu())\n",
        "            action = int(action) # not really necessary\n",
        "             \n",
        "        return action\n",
        "\n",
        "    def test_act(self, state):\n",
        "        ''' To Do: Perform greedy action for the current state for the testing phase\n",
        "            Return : action index in discrete action space, type(action) = int\n",
        "            You will need to call the function: self.forward(state)\n",
        "        '''\n",
        "        state = torch.FloatTensor(np.float32(state)).to(device)\n",
        "        with torch.no_grad():\n",
        "          q_value = self.forward(state)\n",
        "          #print(q_value)\n",
        "          action = np.argmax(q_value.cpu())\n",
        "          action = int(action)\n",
        "        \n",
        "        return action\n",
        "\n",
        "def polyak_update(polyak_factor, target_network, network):\n",
        "    for target_param, param in zip(target_network.parameters(), network.parameters()):\n",
        "        target_param.data.copy_(polyak_factor*param.data + target_param.data*(1.0 - polyak_factor))\n",
        "\n",
        "def compute_td_loss(batch_size, replay_buffer, optimizer, device, model, model_target, gamma, task):\n",
        "    state, action, reward, next_state, done = replay_buffer.sample(batch_size)\n",
        "    state      = torch.FloatTensor(np.float32(state)).to(device)\n",
        "    next_state = torch.FloatTensor(np.float32(next_state)).to(device)\n",
        "    action     = torch.LongTensor(action).to(device)\n",
        "    reward     = torch.FloatTensor(reward).to(device)\n",
        "    done       = torch.FloatTensor(done).to(device)\n",
        "\n",
        "    '''TODO : Implement the DQN/ DDQN algorithm update rule here \n",
        "    You need to define the loss metric as Mean Square Error. \n",
        "    The difference between DQN & DDQN is shown in these steps.\n",
        "    Useful function: in-place operations on tensors 'tensor_a.gather()' , 'tensor_b.unsqueeze()', 'tensor_x.squeeze()' , 'tensor.max()'\n",
        "    with torch.no_grad() ,  .detach()\n",
        "    '''\n",
        "    if task == 1:\n",
        "      q_values = model(state)#.cuda()\n",
        "      next_q_values = model_target(next_state)#.cuda()\n",
        "      q_value          = q_values.gather(1, action.unsqueeze(1)).squeeze(1)\n",
        "      next_q_value     = next_q_values.max(1)[0]\n",
        "      # Q(s,a;theta) = R + gamma * max(Q(s',a';theta^{-}))\n",
        "      expected_q_value = reward + gamma * next_q_value * (1 - done)\n",
        "    else: \n",
        "      # helpful: https://github.com/higgsfield/RL-Adventure/blob/master/2.double%20dqn.ipynb\n",
        "      q_values = model(state)\n",
        "      next_q_values = model(next_state)\n",
        "      next_q_state_values = model_target(next_state)\n",
        "\n",
        "      q_value = q_values.gather(1, action.unsqueeze(1)).squeeze(1)\n",
        "      next_q_value = next_q_state_values.gather(1, torch.max(next_q_values, 1)[1].unsqueeze(1)).squeeze(1)\n",
        "      expected_q_value = reward + gamma * next_q_value * (1- done)\n",
        "      \n",
        "    #loss = torch.nn.MSELoss()\n",
        "    #loss = (q_value - Variable(expected_q_value.data)).pow(2).mean()\n",
        "    crit = torch.nn.MSELoss()\n",
        "    loss = crit(q_value, expected_q_value)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    # Perform soft update (Polyak averaging) with tau = 0.005\n",
        "    # Refer to the post from Navneet_M_Kumar under https://discuss.pytorch.org/t/copying-weights-from-one-net-to-another/1492/16 for answer    \n",
        "    tau = 0.005\n",
        "    model_target = polyak_update(tau, model_target, model)\n",
        "    \n",
        "    return loss\n",
        "\n",
        "\n",
        "def test(env, model):       \n",
        "    ''' \n",
        "        Testing phase.\n",
        "        Only for local users, you can add env.render()\n",
        "    '''\n",
        "    state = env.reset()\n",
        "    episode_reward = 0\n",
        "    # Limit the maximal episode length to avoid infinite loop\n",
        "    for t in range(1000): \n",
        "        action = model.test_act(state)\n",
        "        next_state, reward, done, _ = env.step(action)    \n",
        "        #env.render()        \n",
        "        state = next_state\n",
        "        episode_reward += reward\n",
        "        if done == True:                  \n",
        "            print(\"test reward : {}\".format(episode_reward))\n",
        "            break\n",
        "\n",
        "\n",
        "def plot(frame_idx, rewards, losses, task):\n",
        "    '''\n",
        "        For monitoring the training process\n",
        "    '''\n",
        "    clear_output(True)\n",
        "    plt.figure(figsize=(20,5))\n",
        "    plt.subplot(121)\n",
        "    plt.title('frame %s. reward: %s' % (frame_idx, np.mean(rewards[-10:])))\n",
        "    if task == 1:\n",
        "        plt.plot(rewards)\n",
        "    elif task == 2:\n",
        "        plt.scatter(np.linspace(0,len(rewards)-1,len(rewards)),rewards, s=0.75)\n",
        "    plt.subplot(122)\n",
        "    plt.title('loss')\n",
        "    plt.plot(losses)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":    \n",
        "    '''\n",
        "        Important: The maximal number of interactions: num_frames = 1000000,\n",
        "        But it is definitely NOT NECESSARY to ran until the end.\n",
        "        If the training episodic reward already reaches >-200, then you can STOP the program.\n",
        "        It takes roughly 10 minutes to get converged to episodic reward >-200 in Colab. \n",
        "        You need to write code to save the statistics at the last line of the program.       \n",
        "    '''\n",
        "    task = 2 # to modify\n",
        "    if task == 1:\n",
        "        env = gym.make('MountainCar-v0').env # the suffix .env removes the constraint of maximal episodic length of 200 steps \n",
        "    elif task == 2:\n",
        "        env = gym.make('LunarLander-v2') # An episode will be forced to terminate after 1000 steps in this env setting.\n",
        "    print(env.observation_space, env.action_space)   #observation_space and action space\n",
        "    \n",
        "    # Initialize the exploration strategy/coefficient\n",
        "    epsilon_start = 1.0\n",
        "    epsilon_final = 0.05 # to ensure sufficient exploration \n",
        "    epsilon_decay = 30000 \n",
        "    epsilon_by_frame = lambda frame_idx: epsilon_final + (epsilon_start - epsilon_final) * math.exp(-1. * frame_idx / epsilon_decay)  \n",
        "    # Plot the exploration rate w.r.t. number of steps (frame_index) the agent has traversed. \n",
        "    plt.plot([epsilon_by_frame(i) for i in range(100000)])\n",
        "    \n",
        "    # Initialize the Deep Q-networks\n",
        "    model = DQN(env.observation_space.shape[0], env.action_space.n)\n",
        "    # Declare target network, initialize it \n",
        "    model_target = DQN(env.observation_space.shape[0], env.action_space.n)\n",
        "    \n",
        "    # -->TODO: Copy the weights from model to model_target using 'load_state_dict'\n",
        "    model_target.load_state_dict(model.state_dict())\n",
        "    \n",
        "    # Put networks to GPU\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = model.to(device)\n",
        "    model_target = model_target.to(device)\n",
        "    #Variable = lambda *args, **kwargs: autograd.Variable(*args, **kwargs).cuda()\n",
        "    \n",
        "    # Initialize the optimizer for learning the weights of Neural Network\n",
        "    optimizer = optim.Adam(model.parameters(), lr = 0.001)    \n",
        "    if task == 1:\n",
        "        batch_size = 32\n",
        "        test_every_N_training_episode = 4\n",
        "        start_train = 1000\n",
        "    elif task == 2:\n",
        "        batch_size = 128\n",
        "        test_every_N_training_episode = 10\n",
        "        # Only start training when there is a sufficient number of experience stored in replay buffer\n",
        "        start_train = 3000 \n",
        "    # Initialize the replay buffer with the maximal storage of 1000000 experience/interactions\n",
        "    replay_buffer = ReplayBuffer(1000000)    \n",
        "\n",
        "    gamma = 0.99 # discount factor\n",
        "\n",
        "    # Statistics \n",
        "    losses = []\n",
        "    all_rewards = []\n",
        "    episode_reward = 0\n",
        "    episode_count = 0\n",
        "    episodic_step_count = 0\n",
        "    \n",
        "    \n",
        "    #---------------------Training----------------------\n",
        "    num_frames = 1000000 # maximal number of interactions, similar to N_episodes in previous assignments \n",
        "    state = env.reset()\n",
        "    for frame_idx in range(1, num_frames + 1):\n",
        "        # determine the exploration rate for this step\n",
        "        epsilon = epsilon_by_frame(frame_idx)\n",
        "        # Take an action according to exploration strategy\n",
        "        action = model.act(state, epsilon)\n",
        "        next_state, reward, done, _ = env.step(action)\n",
        "        episodic_step_count += 1\n",
        "        # Add the experience to the replay buffer\n",
        "        if task == 1:\n",
        "            replay_buffer.push(state, action, reward, next_state, done)       \n",
        "        elif task == 2:\n",
        "            # If terminate due to reaching max epi length, we put done as False to replay buffer so to allow bootstrapping of next successor state\n",
        "            if episodic_step_count == env._max_episode_steps:  \n",
        "                replay_buffer.push(state, action, reward, next_state, False)\n",
        "            else:\n",
        "                replay_buffer.push(state, action, reward, next_state, done)\n",
        "        state = next_state\n",
        "        episode_reward += reward\n",
        "\n",
        "        \n",
        "        \n",
        "        if done:\n",
        "            all_rewards.append(episode_reward)\n",
        "            print(\"Episode#:{} reward:{} eps:{}\".format(episode_count,\n",
        "                                     episode_reward, epsilon))\n",
        "            episode_reward = 0\n",
        "            episode_count += 1\n",
        "            episodic_step_count = 0\n",
        "            # ---------------------Test Phase--------------------\n",
        "            if len(all_rewards)%test_every_N_training_episode == test_every_N_training_episode-1:\n",
        "                test(env, model)\n",
        "            #----------------------------------------------\n",
        "            state = env.reset()\n",
        "            \n",
        "            \n",
        "        # Ensure there are enough samples in the replay buffer, then start training the network    \n",
        "        if len(replay_buffer) > start_train:\n",
        "            loss = compute_td_loss(batch_size, replay_buffer, optimizer, device, model, model_target, gamma, task)\n",
        "            losses.append(loss.data)\n",
        "        \n",
        "            \n",
        "        if frame_idx % 1000 == 0:\n",
        "            savePic = plot(frame_idx, all_rewards, losses, task)\n",
        "            # --> TODO: You can save the statistics here\n",
        "            # You could first convert all_rewards and losses into np.array, and save as .npy.file\n",
        "            if frame_idx == 120000:\n",
        "              clear_output(True)\n",
        "              f = plt.figure(figsize=(20,5))\n",
        "              _ = plt.title('frame %s. reward: %s' % (frame_idx, np.mean(all_rewards[-10:])))\n",
        "              if task == 1: \n",
        "                _ = plt.plot(all_rewards)\n",
        "              else:\n",
        "                _ = plt.scatter(np.linspace(0,len(all_rewards)-1,len(all_rewards)),all_rewards, s=0.75)\n",
        "              _ = plt.show()\n",
        "\n",
        "              f.savefig('Lakshith_task2.pdf')\n",
        "              files.download('Lakshith_task2.pdf')\n",
        "              break\n",
        "            "
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_a01d92f9-c7a8-4325-866f-8bb7d20f2a1f\", \"Lakshith_task2.pdf\", 13229)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}